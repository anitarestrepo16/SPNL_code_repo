---
title: "GLMM Sample Size & Power"
author: "Emily Silver"
date: '2022-10-14'
output:
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = FALSE, warning=FALSE)
knitr::opts_knit$set(root.dir = "//ssdfiles.uchicago.edu/normanlab/Students/Emily Silver/Social Threat Study/Power Analysis")
knitr::knit_hooks$set(inline = function(x) {
  x <- sprintf("%1.2f", x)
  paste(x, collapse = ", ")
}) #limit the number of decimal places in inline code
```

```{r cars}
library(ltm)           #Reliability analysis
library(psych)         # Data screening 
library(lme4)          # for running mlm models
library(stats)         # useful add-on statistics 
library(dataMaid)      # for creating data codebooks
library(tidyverse)     # for all things data manipulation
library(ggplot2)       # for all things data visualization
library(lattice)       # more data visualization
library(sjPlot)        # still more data visualization 
library(interactions)  # for probing/plotting interactions
library(lmerTest)      # for p-values
library(glmmTMB)       # extensions for non-standard mlm and graphing
library(mlmRev)        # datasets for hlm including those in the HLM software
library(panelr)        # restructuring datasets
library(corrplot)
library(gvlma)
library(ggpubr)
library(simr)
```


# Tutorial 
## Simulate Data & Covariates
Following this tutorial https://humburg.github.io/Power-Analysis/simr_power_analysis.html

The first step in creating a model for simulation is to create a set of covariates that the model will be based on.

Example study: Children from different classes at a school will be recruited. Each participant will be allocated to either an intervention or a control group. For each participant measurements will be taken at baseline, immediately following the intervention and at follow-up a few weeks later.

```{r}
# We start by setting up a data frame with 5 classes and 10 participants per class.

subj <- factor(1:10)
class_id <- letters[1:5]
time <- 0:2
group <- c("control", "intervention")

subj_full <- rep(subj, 15)
class_full <- rep(rep(class_id, each=10), 3)
time_full <- rep(time, each=50)
group_full <- rep(rep(group, each=5), 15)

covars <- data.frame(id=subj_full, class=class_full, treat=group_full, time=factor(time_full))

covars
```
The next step requires us to specify the parameters for the model. We’ll use the model

y∼treatment+time+treatment×time+(1|class/id)+ϵ

For the purpose of this example parameter values were chosen arbitrarily but should be based on literature or experience as much as possible for real studies.

```{r}
## Intercept and slopes for intervention, time1, time2, intervention:time1, intervention:time2
fixed <- c(5, 0, 0.1, 0.2, 1, 0.9)

## Random intercepts for participants clustered by class
rand <- list(0.5, 0.1)

## residual variance
res <- 2


```
## Create Model  

The makeLmer function from the simr package allows us to combine all this information to create a fitted lmer model from scratch.

```{r}

model <- makeLmer(y ~ treat*time + (1|class/id), fixef=fixed, VarCorr=rand, sigma=res, data=covars)
model


```
Note that the parameters reported as part of the model summary match the ones we provided, except that we specified random effects as variances and they are reported as standard deviations.

## Power Analysis  

Once you have a fitted lmer model, whether it was fitted to real data or created from scratch, you can use that to simulate new data and assess the required sample size.

The powerSim function allows us to estimate the power to detect a specific effect in the model. Here we are interested in the effect of the intervention. Since the treatment variable is part of an interaction we will assess its effect by comparing the model specified above to the the alternative model that doesn’t include a treatment variable. We can provide this model alternative via the fcompare function. This allows us to only specify the fixed effects in the alternative model. All random effects will be assumed to be the same as in the original model.
```{r}
#use powerSim to estimate the power to detect a specific effect in the model for the intervention treatment
sim_treat <- powerSim(model, nsim=100, test = fcompare(y~time))
sim_treat

#We can test for the effect of time in the same way.
sim_time <- powerSim(model, nsim=100, test = fcompare(y~treat))
sim_time
```

## Changing the effect size  

We can adjust the effect size to suit the analysis, e.g. to compute power for an effect size that is smaller than the one observed in a pilot study, or to study power for a range of effect sizes.
```{r}

model_large <- model
fixef(model_large)['treatintervention:time1'] <- 2

sim_treat_large <- powerSim(model_large, nsim=100, test = fcompare(y~time))
sim_treat_large
```
## Changing the number of classes used in study  

To study the effect an increase in sample size has on our ability to detect the effect of interest we can increase the number of levels for one of the factors in our model. This can be achieved with the extend function. For example, we could increase the number of classes from 5 to 20.

We can visualise the effect that varying the number of classes has on the power to detect the intervention effect by asking simr to plot a power curve.
```{r}

#increase number of classes
model_ext_class <- extend(model, along="class", n=20)
model_ext_class

#plot a power curve
sim_treat_class <- powerSim(model_ext_class, nsim=100, test = fcompare(y~time))
sim_treat_class

p_curve_treat <- powerCurve(model_ext_class, test=fcompare(y~time), along="class")
plot(p_curve_treat)


#change the number of participants per class
model_ext_subj <- extend(model, within="class+treat+time", n=20)
model_ext_subj

sim_treat_subj <- powerSim(model_ext_subj, nsim=100, test = fcompare(y~time))
sim_treat_subj

#plot
p_curve_treat <- powerCurve(model_ext_subj, test=fcompare(y~time), within="class+treat+time", breaks=c(5,10,15,20))
plot(p_curve_treat)


```


